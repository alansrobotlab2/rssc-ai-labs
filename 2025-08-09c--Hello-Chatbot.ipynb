{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de57ce1c",
   "metadata": {},
   "source": [
    "## <span style=\"color: rgb(137,207,240)\">Let's Create our First Chatbot</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a822510",
   "metadata": {},
   "source": [
    "Ok, so let's put these two things together -- langgraph and gradio -- to create our first chatbot.\n",
    "\n",
    "First, let's just copy over all the boilerplate langgraph code from lesson 2. Take a quick look at it, then you can minimize the cell by doubleclicking on the left hand margin to tuck it out of the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe70ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2500cada",
   "metadata": {},
   "source": [
    "Ok, now copy over the chatopenai boilerplate code from the previous lesson into the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e602b74b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f718be50",
   "metadata": {},
   "source": [
    "So, we need a function that gradio calls whenever the user enters in some text.  A few things to note in the function.\n",
    "\n",
    "The most important thing is that theres an *impendance mismatch* between chatinterface and llm.invoke.  llm.invoke expects a complete list of messages, but chatinterface passes the current message separately.  So to make this work we append the user message to the list of messages that are passed, then pass the simple response message back.\n",
    "\n",
    "The first pass also has an empty history, so we'll check for that and generate an empty list [] to keep the party going."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd80758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(message, history):\n",
    "    if not history:\n",
    "        history = []\n",
    "    response = llm.invoke(history + [{\"role\": \"user\", \"content\": message}])\n",
    "    return response.content\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2105e4",
   "metadata": {},
   "source": [
    "To save us some time I'm give you the entire one line declaration for your chatbot ui code.\n",
    "\n",
    "Don't stress about that css -- it's just a bit of web wizardry that helps the chat interface to fit into the jupyter notebook cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052373cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a bit of custom CSS to make the chatbot fit in the notebook cell\n",
    "css = \"\"\"\n",
    "#component-7 {\n",
    "    height: 300px !important;\n",
    "    flex-grow: 0 !important;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "demo = gr.ChatInterface(\n",
    "    fn=chatbot, \n",
    "    type=\"messages\", \n",
    "    title=\"My STEM Camp Agent\",\n",
    "    css=css\n",
    ")\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbbad49",
   "metadata": {},
   "source": [
    "##### <span style=\"color: rgb(137,207,240)\">Activity</span>\n",
    "\n",
    "Now to round out this lesson let's add a system message and inject it into the first chatbot call.  Go ahead and update the chatbot cell to initialize history with a system message like we did in the other notebook.\n",
    "\n",
    "Then run the chatbot def cell and the gradio cell below it.  both above this text."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rssc-ai-labs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
